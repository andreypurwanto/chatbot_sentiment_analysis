{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "SAVED_MODEL_PATH = 'saved_model'\n",
    "path_saved_model = os.path.join(os.getcwd(),SAVED_MODEL_PATH)\n",
    "loaded_vectorizer = pickle.load(open(os.path.join(path_saved_model,'chatbot_tfidf_vectorizer.pkl'),'rb'))\n",
    "loaded_model = pickle.load(open(os.path.join(path_saved_model,'chatbot_model.pkl'),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01758826 0.0105855  0.9465413  0.00891716 0.01636778]\n"
     ]
    }
   ],
   "source": [
    "new_complaint = 'help help help help cannot access my invoice'\n",
    "x = loaded_vectorizer.transform([new_complaint])\n",
    "res = loaded_model.predict_proba(x)[0]\n",
    "print(res)\n",
    "# print(loaded_model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user : need to cancel my order help\n",
      "bot : ORDER\n",
      "user : i cant access my account\n",
      "bot : ACCOUNT\n",
      "user : help\n",
      "bot : short_chat\n",
      "user : just an unnecessay comment\n",
      "bot : below_proba\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "EXIT_CHAT = 'exit'\n",
    "model = ''\n",
    "\n",
    "MAP_INDEX_TO_LABEL = {\n",
    "    0 : 'ACCOUNT',\n",
    "    1 : 'CONTACT',\n",
    "    2 : 'INVOICES',\n",
    "    3 : 'ORDER',\n",
    "    4 : 'PAYMENT'\n",
    "}\n",
    "# ['ACCOUNT' 'CONTACT' 'INVOICES' 'ORDER' 'PAYMENT']\n",
    "THRESHOLD = {\n",
    "    'ACCOUNT' : 0.8,\n",
    "    'CONTACT' : 0.8,\n",
    "    'INVOICES' : 0.8,\n",
    "    'ORDER' : 0.8,\n",
    "    'PAYMENT' : 0.8\n",
    "}\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return text\n",
    "\n",
    "def vectorizer(vectorizer):\n",
    "    return vectorizer\n",
    "\n",
    "def inference(model, vectorizer, text) -> dict:\n",
    "    if not model:\n",
    "        # dummy value if model not exist\n",
    "        inference_result = [0,0,0,0.2,0.8]\n",
    "    else:\n",
    "        x = vectorizer.transform([text])\n",
    "        inference_result = model.predict_proba(x)[0]\n",
    "\n",
    "    max_proba = inference_result.max()\n",
    "    index_result = inference_result.argmax(axis=0)\n",
    "    \n",
    "    max_label = MAP_INDEX_TO_LABEL[index_result]\n",
    "    \n",
    "\n",
    "    return {'max_proba' : max_proba, 'max_label' : max_label} # ex {'max_proba' : 0.8, 'max_label' : 'ACCOUNT' }\n",
    "\n",
    "\n",
    "def is_above_threshold(inference_result : dict) -> bool:\n",
    "    if inference_result['max_proba'] > THRESHOLD[inference_result['max_label']]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def exit_chat(text : str) -> bool:\n",
    "    if text == EXIT_CHAT:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def short_chat_rule(text : str) -> bool:\n",
    "    if len(text.split()) < 4:\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "\n",
    "def main(model, vectorizer):\n",
    "    flag = True\n",
    "    while(flag):\n",
    "        user_input = input()\n",
    "        if user_input == 'exit':\n",
    "            flag = False\n",
    "        if flag:\n",
    "            print(f'user : {user_input}')\n",
    "            if not short_chat_rule(user_input):\n",
    "                inference_result = inference(model,vectorizer,user_input)\n",
    "                if is_above_threshold(inference_result):\n",
    "                    response = inference_result['max_label']\n",
    "                else:\n",
    "                    response = 'below_proba'\n",
    "            else:\n",
    "                response = 'short_chat'\n",
    "            print(f'bot : {response}')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # load your model\n",
    "    \n",
    "    main(loaded_model, loaded_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exit to exit chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rakamin_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
